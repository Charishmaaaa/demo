{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNhJjSpVFiFKIYScYbxWWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charishmaaaa/demo/blob/main/ICP6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "data = pd.read_csv('diabetes(1).csv', header=None).values\n",
        "\n",
        "X = data[:, 0:8]\n",
        "y = data[:, 8]\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=87)\n",
        "\n",
        "np.random.seed(155)\n",
        "\n",
        "\n",
        "my_nn = Sequential()\n",
        "\n",
        "\n",
        "my_nn.add(Dense(20, input_dim=8, activation='relu'))\n",
        "my_nn.add(Dense(20, activation='relu'))\n",
        "my_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "my_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "my_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "print(my_nn.summary())\n",
        "\n",
        "\n",
        "evaluation = my_nn.evaluate(X_test, Y_test)\n",
        "print(\"Test Loss:\", evaluation[0])\n",
        "print(\"Test Accuracy:\", evaluation[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW78gOO_7R8r",
        "outputId": "2c2b0023-336c-402f-a5a5-cc87aa3aae16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 2ms/step - loss: 4.7878 - accuracy: 0.5799\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.0614 - accuracy: 0.5347\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.4901 - accuracy: 0.5590\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.2446 - accuracy: 0.5868\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0600 - accuracy: 0.6111\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9398 - accuracy: 0.6215\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8287 - accuracy: 0.6094\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8222 - accuracy: 0.6597\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7963 - accuracy: 0.6076\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7292 - accuracy: 0.6319\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7437 - accuracy: 0.6389\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7170 - accuracy: 0.6562\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.6562\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.6736\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6667\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6858\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6736\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.6840\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.7049\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6840\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6719\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.7274\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7014\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6840\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5904 - accuracy: 0.7222\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6175 - accuracy: 0.6997\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6962\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7083\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6806\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7049\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5669 - accuracy: 0.7170\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7014\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7014\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.6806\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.6858\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5693 - accuracy: 0.7101\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.7049\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5811 - accuracy: 0.7014\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5859 - accuracy: 0.7118\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5783 - accuracy: 0.7118\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5602 - accuracy: 0.7118\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6222 - accuracy: 0.6910\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5624 - accuracy: 0.7188\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5599 - accuracy: 0.7135\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5410 - accuracy: 0.7222\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7014\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7170\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.6858\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7014\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7101\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7031\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7222\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7222\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7344\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7396\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7413\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7431\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7483\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7517\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7413\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7188\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7083\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7240\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7431\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7135\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7396\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7309\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7222\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7309\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7483\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7240\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7465\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7205\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7361\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7344\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7292\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.6997\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7378\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7517\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7170\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7483\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7396\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7326\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7587\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7465\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7396\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7413\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7465\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7361\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7257\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7517\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7413\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7240\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7361\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7326\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7396\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 621 (2.43 KB)\n",
            "Trainable params: 621 (2.43 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6406\n",
            "Test Loss: 0.6488111615180969\n",
            "Test Accuracy: 0.640625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "data = pd.read_csv('diabetes(1).csv', header=None).values\n",
        "\n",
        "X = data[:, 0:8]\n",
        "y = data[:, 8]\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=87)\n",
        "\n",
        "np.random.seed(155)\n",
        "\n",
        "\n",
        "my_nn = Sequential()\n",
        "\n",
        "\n",
        "my_nn.add(Dense(20, input_dim=8, activation='tanh'))\n",
        "my_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "my_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "my_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "\n",
        "print(my_nn.summary())\n",
        "\n",
        "\n",
        "evaluation = my_nn.evaluate(X_test, Y_test)\n",
        "print(\"Test Loss:\", evaluation[0])\n",
        "print(\"Test Accuracy:\", evaluation[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZMtFIHR7jnm",
        "outputId": "b798aa2b-089f-4db6-d835-c100b7b31141"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 2ms/step - loss: 0.8247 - accuracy: 0.6597\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7693 - accuracy: 0.6597\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.6597\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6615\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.6597\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6632\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6562\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6580\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6493\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6493\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6510\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6510\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.6562\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6597\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6719\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6736\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6684\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6736\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6753\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6806\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6997\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.6858\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6823\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6910\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6927\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6927\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.6927\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.6892\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.6962\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.6910\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7188\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7135\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7066\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7205\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7066\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7101\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7083\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7222\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7188\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7205\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7188\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7101\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7170\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7135\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7118\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7101\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7031\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7205\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7222\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7222\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7292\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7292\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7240\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7274\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7240\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7240\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7344\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7326\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7257\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7205\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7326\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7274\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7257\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7222\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7205\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7257\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7240\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7205\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7205\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7292\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7274\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7257\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7257\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7309\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7257\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7326\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7188\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7326\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7309\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7292\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7257\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7309\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7326\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7378\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7309\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7344\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7326\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7240\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7326\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7326\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7257\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7344\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7274\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7309\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7309\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7326\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7292\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7274\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201 (804.00 Byte)\n",
            "Trainable params: 201 (804.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6927\n",
            "Test Loss: 0.5895751118659973\n",
            "Test Accuracy: 0.6927083134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the feature scaling step\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=87)\n",
        "\n",
        "# Rest of the code remains the same\n"
      ],
      "metadata": {
        "id": "a0cxZUee_QhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "sample_image = X_test[1]\n",
        "\n",
        "\n",
        "plt.imshow(sample_image.reshape(1, -1), cmap='gray')\n",
        "plt.title(\"Sample Image\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "prediction = my_nn.predict(np.array([sample_image]))\n",
        "\n",
        "\n",
        "if prediction[0][0] >= 0.5:\n",
        "    print(\"The model predicts diabetes.\")\n",
        "else:\n",
        "    print(\"The model predicts no diabetes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "8ROpQyZx_eWX",
        "outputId": "c25e824c-7839-44c1-b54d-6ad434145e30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "The model predicts diabetes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O00SCu9-_vDS",
        "outputId": "4df714d9-ed25-47f9-e6f6-3ab58d63c688"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.2917 - accuracy: 0.9099 - val_loss: 0.1738 - val_accuracy: 0.9430\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.1000 - accuracy: 0.9696 - val_loss: 0.0801 - val_accuracy: 0.9750\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0627 - accuracy: 0.9806 - val_loss: 0.0793 - val_accuracy: 0.9740\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.1047 - val_accuracy: 0.9691\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.0595 - val_accuracy: 0.9811\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0727 - val_accuracy: 0.9795\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0767 - val_accuracy: 0.9790\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0658 - val_accuracy: 0.9824\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0769 - val_accuracy: 0.9811\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0725 - val_accuracy: 0.9818\n"
          ]
        }
      ]
    }
  ]
}